<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Machine learning</title>

<script src="site_libs/header-attrs-2.9/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Data Science Notes</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Sections
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="newlab2.html">Intro to R</a>
    </li>
    <li>
      <a href="newlab3.html">Commands and functions</a>
    </li>
    <li>
      <a href="newlab4.html">Data massaging: basics</a>
    </li>
    <li>
      <a href="newlab5.html">Intro to programming</a>
    </li>
    <li>
      <a href="newlab6.html">ggplot2</a>
    </li>
    <li>
      <a href="newlab7.html">Data transformations I</a>
    </li>
    <li>
      <a href="newlab8.html">Data transformations II</a>
    </li>
    <li>
      <a href="newlab9.html">Data cleaning</a>
    </li>
    <li>
      <a href="newlab10.html">Random variables</a>
    </li>
    <li>
      <a href="newlab11.html">Discrete and continous random variables</a>
    </li>
    <li>
      <a href="newlab12.html">Mean and variance</a>
    </li>
    <li>
      <a href="newlab14.html">Confidence Intervals</a>
    </li>
    <li>
      <a href="newlab15.html">Hypothesis Testing</a>
    </li>
    <li>
      <a href="newlab16.html">Regression</a>
    </li>
    <li>
      <a href="newlab18.html">Machine learning</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Machine learning</h1>

</div>


<div id="machine-learning" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Machine learning</h1>
<p>The field of <strong>machine learning</strong> began to take hold around the middle of the 20th century. Like the field of computer science, mathematicians were at the forefront of laying the foundations which have eventually led to the many creature comforts we are experiencing today. Every time you cash a check at an ATM or on a cell phone, for instance, a machine learning is at work, using loads of previous written digits as training data to guess what you <em>meant</em> to write with astounding accuracy. Almost every major business uses machine learning to direct you to finding the right person to speak to on the telephone (alright, alright, often that process is incredibly annoying, but apparently it cuts down on total time on the phone, or the business wouldn’t be using it). Phone apps use machine learning to identify songs after a few seconds. There’s even an app for identifying species by simply taking a snapshot in a garden! Machine learning will be at the forefront of what types of jobs we will all be doing in the future.</p>
<p>It won’t all be roses, of course. Plenty will be displaced, and it’s a serious question of what we’re going to do with truckers when self driving cars are prevalent. Other professions that you might not expect may be on the chopping block too. Machine learning algorithms are already beating doctors in identifying tumors, and there are plenty of opportunities for automation to replace soldiers (this too, is loaded with ethical dilemmas). It’s unfortunate that the reduction of labor, what of first blush seems to be an absolute good, might cause a good deal of hardship in the future. Data scientists are obviously going to be needed in developing all of this automation, but we’ll also need very bright people to figure out how to transition through this with as little turbulence as possible.</p>
<p>Alright, enough of the doom and gloom. Let’s get into the meat of machine learning. We’re going to go over the bare bones of two basic methods in machine learning, <strong>k-means</strong> and <strong>k-nearest neighbors</strong>.</p>
</div>
<div id="k-nearest-neighbors" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> <span class="math inline">\(k\)</span>-nearest neighbors</h1>
<p>The algorithm of <span class="math inline">\(k\)</span>-nearest neighbors (Knn) is a type of <strong>clustering algorithm</strong>. The main question is as follows: Given a element with certain features, predict a labeling. Knn, unlike logistic regression, is <strong>nonparametric</strong>. The <span class="math inline">\(k\)</span> in <span class="math inline">\(k\)</span>-nearest neighbors gives a <strong>tuning parameter</strong>. This is something we start off with–in parametrized models we <em>learn</em> the parameter through training.</p>
<p>The idea is that given a point, we predict its label by guessing the labels of nearby datapoints in the training set. We can visualize a decision boundary in two dimension, but it is still possible to preform this in high dimensions.</p>
<p>A few points before we dig in:</p>
<ol style="list-style-type: decimal">
<li>The distance between two datapoints has a great deal of wiggle room. We can define a distance using any <strong>metric</strong> <span class="math inline">\(d(x,y)\ge 0\)</span> satisfying</li>
</ol>
<p>Examples abound. For two vectors, the most common metric is the <strong>Euclidean metric</strong> <span class="math display">\[\begin{equation}
d(\mathbf x, \mathbf y) = \sqrt{(x_1-y_1)^2+(x_2-y_2)^2+\dots+(x_n-y_n)^2}.
\end{equation}\]</span></p>
<center>
<div class="figure">
<img src="knn.png" alt="" />
<p class="caption">An example of knn with k = 3 and k = 5 (Image courtesy of Wikipedia)</p>
</div>
</center>
<blockquote>
<p><strong>Q:</strong> Under different <span class="math inline">\(k\)</span>, how ought we label the unclassified green circle?</p>
</blockquote>
</div>
<div id="knn-on-the-iris-dataset" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Knn on the iris dataset</h1>
<p>We’ll need the &lt;<T>&gt;class&lt;</T>&gt; package for running knn.</p>
<pre class="r"><code>library(class)</code></pre>
<pre class="r"><code># Some minor changes in the data set

# Normalizing variables

#Question: what does the -5 mean?
dataNorm = iris
dataNorm[,-5] = scale(iris[,-5])


#To make sure we can get repeatable (reproducible) results

set.seed(1234)


#This is picking (approximately) 70% of data to be training data.  
#What should you do if you always want fraction to be the same?
ind = sample(2, nrow(dataNorm), replace = TRUE, prob = c(.7, .3))

trainData = dataNorm[ind == 1, ]

testData = dataNorm[ind == 2, ]



#knn with k = 3
Knntestpredict = knn(trainData[,-5], testData[,-5],
                        trainData$Species, k = 3, prob = TRUE)

Knntestpredict</code></pre>
<pre><code>##  [1] setosa     setosa     setosa     setosa     setosa     setosa    
##  [7] setosa     setosa     setosa     setosa     versicolor versicolor
## [13] versicolor versicolor versicolor versicolor versicolor versicolor
## [19] versicolor versicolor versicolor versicolor virginica  virginica 
## [25] virginica  virginica  versicolor virginica  virginica  virginica 
## [31] virginica  virginica  versicolor virginica  virginica  virginica 
## [37] virginica  virginica 
## attr(,&quot;prob&quot;)
##  [1] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
##  [8] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
## [15] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
## [22] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
## [29] 1.0000000 1.0000000 0.6666667 1.0000000 0.6666667 1.0000000 1.0000000
## [36] 1.0000000 0.6666667 1.0000000
## Levels: setosa versicolor virginica</code></pre>
<p>Here is the <strong>confusion matrix</strong></p>
<pre class="r"><code>table(testData$Species, Knntestpredict)</code></pre>
<pre><code>##             Knntestpredict
##              setosa versicolor virginica
##   setosa         10          0         0
##   versicolor      0         12         0
##   virginica       0          2        14</code></pre>
<p>The rows represent the actual species of plant, and the columns represent the estimates from knn. The more entries on the diagonal, the better. In our case, for <span class="math inline">\(k = 3\)</span>, we have correctly classified <span class="math inline">\(10+12+14 = 36\)</span> plants. Two virginicas, however, have been misclassified as versicolor.</p>
<blockquote>
<p><strong>Q:</strong> For different values of <span class="math inline">\(k\)</span>, how does our confusion matrix perform. Is it true that the higher the <span class="math inline">\(k\)</span>, the better? What happens when <span class="math inline">\(k\)</span> becomes very large?</p>
</blockquote>
</div>
<div id="k-means" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> K-means</h1>
<p>The history of k-means is quite old: it goes at least as far back as the Polish mathematician Hugo Steinhaus in the 1950’s. The point of <span class="math inline">\(k\)</span>-means is to do clustering without training. This means that our data is not labeled. It is simply a collection of points in some space. After initializing with <span class="math inline">\(k\)</span> centroids, the two steps to k-means are</p>
<ol style="list-style-type: decimal">
<li><p>(Labeling) Compute a <strong>Voronoi diagram</strong> for centroids <span class="math inline">\(x_1, \dots, x_k\)</span>. This produces cells which partition <span class="math inline">\(C_1, \dots, C_k\)</span> the plane and have the minimum distance property <span class="math display">\[\begin{equation}
x\in C_k \Rightarrow d(x,x_k) \le d(x,x_i), \quad i \neq k.
\end{equation}\]</span></p></li>
<li><p>(Update) Reposition centroids to the average position of points in the Voronoi cells. <span class="math display">\[\begin{equation}
\frac{1}{|C_k|}\sum_{x \in C_k} x\leftarrow x_k .
\end{equation}\]</span> \end{enumerate}</p></li>
</ol>
<p>The goal is to try clustering points which are close to each other. For a measure, we want to minimize</p>
<p><span class="math display">\[\begin{equation}
\sum_{i = 1}^k \sum_{x \in x_k} d(x,x_k).
\end{equation}\]</span></p>
<p>This minimization ensures that points in a cluster to be close to eachother, but points from two different clusters to be far apart as possible. K-means will converge to some local minimum of (3), but this may not be the global minimum.</p>
<div id="a-clear-example-in-two-d" class="section level2" number="4.1">
<h2 number="4.1"><span class="header-section-number">4.1</span> A clear example in two-d</h2>
<p>Let’s generate some points in which it should be clear how k-means will work</p>
<pre class="r"><code>pts &lt;- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
           matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
colnames(pts) &lt;- c(&quot;x&quot;, &quot;y&quot;)

X = data.frame(pts)

#testing for 8 clusters
cl &lt;- kmeans(pts, 2)

X$cluster = as.character(cl$cluster)

X %&gt;% ggplot(aes(x,y, color = cluster)) + geom_point()</code></pre>
<p><img src="newlab18_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<blockquote>
<p><strong>Q:</strong> Obviously, <span class="math inline">\(k = 8\)</span> isn’t the right <span class="math inline">\(k\)</span>. What is the correct <span class="math inline">\(k\)</span>?</p>
</blockquote>
</div>
<div id="iris-dataset-and-k-means" class="section level2" number="4.2">
<h2 number="4.2"><span class="header-section-number">4.2</span> Iris dataset and k-means</h2>
<p>What happens if we try classifying the iris dataset by k-means? This is a bit odd, since we are not using the labels at all!</p>
<pre class="r"><code>clust = kmeans(scale(iris[-5]), 3)

clust$cluster</code></pre>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
##  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2
##  [75] 2 3 3 3 2 2 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3
## [112] 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 3 3 3 3 3 3 2 2 3 3 3 2 3 3 3 2 3 3 3 2 3
## [149] 3 2</code></pre>
<pre class="r"><code>Z = data.frame(clust$cluster, iris$Species)

#Let&#39;s tally what each cluster gets

tally = matrix(0,3,3)

for (i in 1:dim(Z)[1]){
  q = Z[i,1]
  tally[q,1] = tally[q,1]+ (Z[i,2] == &#39;setosa&#39;)
  tally[q,2] = tally[q,2] + (Z[i,2] == &#39;versicolor&#39;)
  tally[q,3] = tally[q,3] +(Z[i,2] == &#39;virginica&#39;)
  
}


print(tally)</code></pre>
<pre><code>##      [,1] [,2] [,3]
## [1,]   50    0    0
## [2,]    0   39   14
## [3,]    0   11   36</code></pre>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
